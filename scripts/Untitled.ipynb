{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5fbaa81-00c3-4a25-afad-c0ee522a5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark import SparkConf \n",
    "from pyspark.sql import SparkSession # https://spark.apache.org/docs/1.6.1/sql-programming-guide.html\n",
    "from pyspark.sql import functions as F # access to the sql functions https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "731ecbc9-c3d6-441a-9e40-6e57b6f4d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data/spark-warehouse\n",
      "-Dderby.system.home=/home/jovyan/data/spark-warehouse\n"
     ]
    }
   ],
   "source": [
    "# To persist our sparksql data from session to session we will use derby.\n",
    "warehouse_location = os.path.abspath('../data/spark-warehouse')\n",
    "java_options = \"-Dderby.system.home=\" + warehouse_location\n",
    "print(warehouse_location)\n",
    "print(java_options)\n",
    "# make sure you have set the warehouse location to 'home/jovyan/data/spark-warehouse'\n",
    "\n",
    "if os.path.normpath(\"/home/jovyan/data/spark-warehouse\") != warehouse_location:\n",
    "    print('\\x1b[6;37;41m' + 'Your path is not correct' + '\\x1b[0m')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf55a1-21e4-4acb-b38d-e9f4b9249c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69ddaa8c-13c3-4d17-8b56-5c67164f8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create the session\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.ui.port\", \"4041\")\n",
    "    .set('spark.jars', '/home/jovyan/scratch/postgresql-42.2.18.jar')\n",
    "    .set(\"spark.sql.warehouse.dir\", warehouse_location) # set above.\n",
    "    .set(\"hive.metastore.schema.verification\", False)\n",
    "    .set(\"javax.jdo.option.ConnectionURL\", \"jdbc:derby:;databaseName=metastore_db;create=true\") # settings to persist data for sparksql\n",
    "    .set(\"javax.jdo.option.ConnectionDriverName\", \"org.apache.derby.jdbc.EmbeddedDriver\") # settings to persist data for sparksql\n",
    "    .set(\"javax.jdo.option.ConnectionUserName\", 'userman') # may not need this\n",
    "    .set(\"jdo.option.ConnectionPassword\", \"pwd\") # may not need this\n",
    "    .set(\"spark.driver.extraJavaOptions\",java_options) # setting where the derby log files are created.\n",
    "    .set(\"spark.sql.inMemoryColumnarStorage.compressed\", True) # default\n",
    "    .set(\"spark.sql.inMemoryColumnarStorage.batchSize\",10000) # default\n",
    "    )\n",
    "\n",
    "# Create the Session (used to be context)\n",
    "# you can move the number up or down depending on your memory and processors \"local[*]\" will use all.\n",
    "# The conf from above is used in .config.\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[7]\") \\\n",
    "    .appName('test') \\\n",
    "    .config(conf=conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "519a4c8a-f74c-4b18-86e2-7eb4777b7850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('DROP DATABASE library CASCADE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "679dd189-72a2-4fe3-9888-db91775e7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.stop()\n",
    "# spark.sql('DROP DATABASE IF EXISTS irs990 CASCADE;')\n",
    "# spark.sql(\"create database irs990\")\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4897e4-9da6-4ab0-95d6-a726b7232ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e4090-4c0b-4f67-b405-e25db7ffd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56997dc8-e0c6-4940-bf4f-281afacc47c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " spark.sql(\"CREATE DATABASE library;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1d06bad-9296-4b92-8347-4f03f38f1850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "| BibNum|               Title|              Author|                ISBN|PublicationYear|           Publisher|            Subjects|ItemType|ItemCollection|FloatingItem|ItemLocation|ReportDate|ItemCount|\n",
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "|2661617|Kindergarten diar...|  Portis, Antoinette|0061456918, 00614...|         [2010]|      HarperCollins,|Kindergarten Juve...|    jcbk|         ccpic|          NA|         cen|01/01/2020|        2|\n",
      "| 321202|The sex life, bef...|Sadler, William S...|                null|          1938.|American Pub. Corp.,|Sex, Sexual healt...|    acbk|           cs6|          NA|         cen|01/01/2020|        1|\n",
      "| 287899|Plank-on-frame mo...|Underhill, Harold A.|                null|     1958-1960.|Brown, Son and Fe...|         Ship models|    arbk|          cs7r|          NA|         cen|01/01/2020|        2|\n",
      "|3296522|Rufus blasts off!...|    Griswell, Kim T.|1454920998, 97814...|         [2017]|Sterling Children...|Swine Juvenile fi...|    jcbk|         ncpic|          NA|         nga|01/01/2020|        1|\n",
      "|3305063|Sword song : the ...|   Cornwell, Bernard|0061379743, 97800...|         [2009]|             Harper,|Alfred King of En...|    acbk|         nafic|          NA|         swt|01/01/2020|        1|\n",
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#spark.sql(\"USE library\")\n",
    "#collection = spark.read.format(\"csv\").load(\"../data/big/Library_Collection_Inventory.csv\")\n",
    "#print(collection.limit(5))\n",
    "#collection.write.mode(\"overwrite\").saveAsTable(\"collection\")\n",
    "\n",
    "spark.sql(\"USE library\")\n",
    "collection = spark.read.csv(path= \"../data/big/Library_Collection_Inventory.csv\", header = True)\n",
    "print(collection.limit(5).show(5))\n",
    "collection.write.mode(\"overwrite\").saveAsTable(\"collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4540ed40-5fb0-4f76-9855-201dfbb21452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+------------+-------------+---------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|UsageClass|CheckoutType|MaterialType|CheckoutYear|CheckoutMonth|Checkouts|               Title|             Creator|            Subjects|           Publisher|PublicationYear|\n",
      "+----------+------------+------------+------------+-------------+---------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|   Digital|   OverDrive|       EBOOK|        2018|            4|        1|     The Storyteller|   Antonia Michaelis|Mystery, Young Ad...|              ABRAMS|           2013|\n",
      "|   Digital|   OverDrive|   AUDIOBOOK|        2018|            4|       32|How Not to Be Wro...|    Jordan Ellenberg|Mathematics, Nonf...|       Books on Tape|           2014|\n",
      "|  Physical|     Horizon|        BOOK|        2018|            4|       18|Rick Steves best ...| Steves, Rick, 1955-|Spain Guidebooks,...|Avalon Travel, Ha...|         [2018]|\n",
      "|  Physical|     Horizon|        BOOK|        2018|            4|        5|The treasure box ...|Wild, Margaret, 1...|Refugees Juvenile...|   Candlewick Press,|          2017.|\n",
      "|  Physical|     Horizon|        BOOK|        2018|            4|        5|Welcome to Mamoko...|Mizielińska, Alek...|Stories without w...|  Big Picture Press,|          2013.|\n",
      "+----------+------------+------------+------------+-------------+---------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#spark.sql(\"USE library\")\n",
    "#checkouts = spark.read.format(\"csv\").load(\"../data/big/Checkouts_by_Title.csv\")\n",
    "#print(checkouts.limit(5))\n",
    "#checkouts.write.mode(\"overwrite\").saveAsTable(\"checkouts\")\n",
    "\n",
    "\n",
    "spark.sql(\"USE library\")\n",
    "collection = spark.read.csv(path=\"../data/big/Checkouts_by_Title.csv\",header=True)\n",
    "print(collection.limit(5).show(5))\n",
    "collection.write.mode(\"overwrite\").saveAsTable(\"checkouts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c98611f1-836b-44d5-afcc-5a110eb3f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "| BibNum|               Title|              Author|                ISBN|PublicationYear|           Publisher|            Subjects|ItemType|ItemCollection|FloatingItem|ItemLocation|ReportDate|ItemCount|\n",
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "|2940791|Baby Beatles! / C...|   Babypants, Caspar|                null|         [2013]|Aurora Elephant M...|Childrens songs J...|    jccd|          nccd|    Floating|         bea|12/01/2017|        1|\n",
      "|2994551|Living simple, fr...|Frank, Cristin, 1...|1440325251, 97814...|         [2013]|Betterway Home Bo...|Home economics, H...|    acbk|          nanf|          NA|         rbe|12/01/2017|        1|\n",
      "|2455016|That special litt...| Peddicord, Jane Ann|0152054308, 97801...|          2007.|           Harcourt,|Babies Fiction, T...|    jcbk|         ccpic|          NA|         cen|12/01/2017|        1|\n",
      "|1338172|Semʹ dneĭ tvoreni...|Maksimov, Vladimi...|                null|          1973.|              Posev,|                null|    acbk|          caln|          NA|         cen|12/01/2017|        1|\n",
      "|2980545|The Masnavi : boo...|Jalāl al-Dīn Rūmī...|0199549915, 97801...|          2008.|Oxford University...| Sufi poetry Persian|    acbk|          canf|          NA|         cen|12/01/2017|        1|\n",
      "+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------+--------------+------------+------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"SELECT * FROM collection LIMIT 5 ORDER\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa7bbdf6-7044-4313-ad8f-cd74e6f53898",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: collection.COLUMNS; line 1 pos 24;\n'Project ['COLUMN_NAME]\n+- 'Filter ('TABLE_NAME = 'collection)\n   +- 'UnresolvedRelation [collection, COLUMNS], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7c6d7c5c7b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT COLUMN_NAME FROM collection.COLUMNS WHERE TABLE_NAME = collection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: collection.COLUMNS; line 1 pos 24;\n'Project ['COLUMN_NAME]\n+- 'Filter ('TABLE_NAME = 'collection)\n   +- 'UnresolvedRelation [collection, COLUMNS], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COLUMN_NAME\n",
    "FROM collection.COLUMNS\n",
    "WHERE TABLE_NAME = collection\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7665401d-e3a5-4e93-9784-3ea29194b912",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0a0a569e719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/spark-warehouse/library.db/collection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dat = pd.read_parquet(\"../data/spark-warehouse/library.db/collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd648b1e-c1a5-4492-946d-9e69f5a2a872",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d794c87236c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#checkouts.plot(kind='scatter', x = 'Author', y = 'Publisher')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPublisher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# OR (with pandas 0.13 and up)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#df.plot(kind='scatter', x='col1', y='col2', s=df.col3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#checkouts.scatter(x = Author,y = Checkouts)\n",
    "\n",
    "#checkouts.plot(kind='scatter', x = 'Author', y = 'Publisher')\n",
    "\n",
    "#plt.scatter(checkouts.Author, checkouts.Publisher)\n",
    "# OR (with pandas 0.13 and up)\n",
    "#df.plot(kind='scatter', x='col1', y='col2', s=df.col3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b55fb8-7200-4f00-9e6c-6e44b8f9b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f987f0f-7dfb-400d-9c6a-f129945bd86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
